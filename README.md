# Atomic

A sound and fast distributed version control system based on a mathematical theory of asynchronous work. Atomic is designed to handle distributed version control with a focus on mathematical correctness and performance.

## üöÄ AI-Scale Workflow Optimization (Revolutionary Architecture)

Atomic introduces a **hybrid patch-snapshot model** that solves the fundamental scalability challenge of version control systems in AI-centric development environments. While traditional patch systems suffer from exponential dependency growth and Git's snapshot model loses semantic precision, Atomic combines the best of both worlds.

### The Scalability Breakthrough: Tag-Based Dependency Consolidation

**The Problem**: With 100+ AI agents and developers working over years, traditional patch systems accumulate dependencies exponentially, making operations computationally prohibitive.

**Atomic's Solution**: **Consolidating Tags** that act as mathematical snapshots while preserving patch precision:

```
=== Sprint 1: Normal Patch Development ===
Change 1 ‚Üí [no deps]
Change 2 ‚Üí [Change 1]  
Change 3 ‚Üí [Change 1, Change 2]
...
Change 25 ‚Üí [Changes 1-24]  // 24 dependencies

üè∑Ô∏è TAG v1.0 [CONSOLIDATING] ‚Üí Mathematical snapshot of all 25 changes

=== Sprint 2: Clean Dependency Chains ===
Change 26 ‚Üí [TAG v1.0] ‚ú® Single dependency from tag!
Change 27 ‚Üí [Change 26]
Change 28 ‚Üí [Change 26, Change 27]
```

**Result**: Bounded dependency growth + mathematical precision within cycles + snapshot-like scalability across cycles.

### AI-Optimized Architecture Benefits

#### 1. **Concurrent AI Agent Coordination**
```bash
# Multiple AI agents work from same clean baseline
BASELINE=$(atomic tag list --consolidating --latest)

atomic fork --state $BASELINE ai-agent-refactor
atomic fork --state $BASELINE ai-agent-security  
atomic fork --state $BASELINE ai-agent-docs

# Each agent has minimal dependencies: [BASELINE] only
atomic record --channel ai-agent-refactor -m "AI: Performance optimization"
atomic record --channel ai-agent-security -m "AI: Security audit"
atomic record --channel ai-agent-docs -m "AI: Documentation generation"

# Create next consolidating tag
atomic tag create --consolidate "sprint-2-complete" -m "Sprint 2 Complete - AI Enhancements"
```

#### 2. **Production Hotfix Workflows**
```bash
# Apply security fix to old production version
atomic fork v1.0 security-hotfix
atomic record --channel security-hotfix -m "SECURITY: Fix authentication bypass"

# Automatically propagate to ALL affected versions
atomic apply --to-tag v1.0 --create-tag v1.0.1 <hotfix-changes>
atomic propagate-hotfix v1.0.1 --to-descendants
# Creates: v1.0.1, v2.0.1, v3.0.1, current-dev-patched
```

#### 3. **AI Attribution Intelligence at Scale**
Atomic preserves detailed AI attribution through consolidation using high-performance **Sanakirja btree storage**:

```bash
# Lightning-fast attribution queries across consolidation cycles
atomic attribution --tag-range v1.0..v5.0 --ai-trends
atomic attribution --provider-comparison openai anthropic --since-tag v2.0
atomic attribution --confidence-analysis --consolidation-cycles 10

# Detailed audit trails preserved for compliance
atomic attribution --tag v3.0 --detailed --provider github
```

### Why This Architecture Is Impossible in Git

1. **No Mathematical Dependency Tracking**: Git can't guarantee semantic consistency across complex merges
2. **No Automatic Conflict Resolution**: Requires manual intervention for every merge conflict
3. **No Granular Change Selection**: Either merge entire branches or nothing
4. **No AI Workflow Coordination**: No native understanding of AI vs human contributions
5. **No Production Hotfix Automation**: Manual cherry-picking across multiple branches

### The Mathematical Foundation

Atomic's consolidating tags provide **mathematical guarantees**:
- **Commutativity**: Changes can be applied in different orders
- **Associativity**: Grouping of changes doesn't affect final result  
- **Consistency**: Same logical change applies correctly to all compatible states
- **Completeness**: Automatic detection of all affected consolidation points
- **Attribution Preservation**: AI contributions tracked through all operations

**The result**: A version control system that scales to enterprise AI development while maintaining mathematical correctness and unprecedented AI development intelligence.

üîó **[Read the complete workflow specification ‚Üí](docs/New-Workflow-Recommendation.md)**

## ü§ñ AI Attribution System (Phase 2 Complete)

Atomic is pioneering the first mathematically sound AI attribution system built directly into version control. Unlike external tracking systems, our attribution travels with semantic changes (patches) through the distributed system, ensuring AI contributions are never lost during merges or conflicts.

**Key Innovation**: Attribution as first-class patch metadata, not commit metadata.

üîó **[Read the full AI Attribution MVP specification ‚Üí](docs/AI_EDIT_MVP.md)**

### How It Works Today

The attribution system is now integrated into Atomic's change recording workflow. Here's how you can use it:

#### CLI Integration (Available Now)
```bash
# Record an AI-assisted change
atomic record --ai-assisted --ai-provider openai --ai-model gpt-4 -m "Implement user authentication"

# Specify suggestion type and confidence
atomic record --ai-assisted \
  --ai-provider anthropic \
  --ai-model claude-3 \
  --ai-suggestion-type collaborative \
  --ai-confidence 0.87 \
  -m "Refactor database layer"

# Record AI review of human code
atomic record --ai-assisted \
  --ai-provider github \
  --ai-model copilot \
  --ai-suggestion-type review \
  -m "Fix security vulnerabilities found by AI review"

# All AI suggestion types available:
# --ai-suggestion-type complete      # AI generated the entire patch
# --ai-suggestion-type partial       # AI suggested, human modified  
# --ai-suggestion-type collaborative # Human started, AI completed
# --ai-suggestion-type inspired      # Human wrote based on AI suggestion
# --ai-suggestion-type review        # AI reviewed human code
# --ai-suggestion-type refactor      # AI refactored existing code
```

#### Environment Variable Detection (Available Now)
```bash
# Basic AI development environment
export ATOMIC_AI_ENABLED=true
export ATOMIC_AI_PROVIDER=openai
export ATOMIC_AI_MODEL=gpt-4
export ATOMIC_AI_SUGGESTION_TYPE=collaborative

# Now all changes automatically capture AI attribution
atomic record -m "Implement new feature with AI assistance"
```

#### Configuration File Support (Available Now)
```toml
# .atomic/config.toml - Repository-specific config
[ai_attribution]
enabled = true
provider = "anthropic"
model = "claude-3"
track_prompts = true
require_confirmation = false

# ~/.config/atomic/config.toml - User-wide config
[ai_attribution]
enabled = true
provider = "openai"
model = "gpt-4"
track_prompts = true
require_confirmation = true  # Prompt for confirmation on AI changes
```

### What's Tracked

Each attributed patch captures:
- **Provider & Model**: Which AI system assisted (OpenAI GPT-4, Anthropic Claude, etc.)
- **Suggestion Type**: Complete, Partial, Collaborative, Inspired, Review, or Refactor
- **Confidence Score**: How confident the system is in the attribution (0.0-1.0)
- **Human Review Time**: Time spent by humans reviewing AI suggestions
- **Token Usage**: For cost and usage tracking
- **Model Parameters**: Temperature, max tokens, etc. used for generation

### Implementation Status & Roadmap

‚úÖ **Phase 1**: Core attribution types and database tables
‚úÖ **Phase 2**: CLI integration and environment detection
üöß **Phase 3**: Database persistence and patch application (In Progress)
üìã **Phase 4**: Remote sync and conflict resolution
üìã **Phase 5**: Analytics and reporting tools

#### What's Coming Next

**Phase 3 - Features** (Current Focus):
```bash
# Query attribution history and statistics
atomic attribution --stats --providers --suggestion-types

# Show attribution for specific AI provider
atomic attribution --filter-provider openai --min-confidence 0.8

# Analyze attribution for specific change
atomic attribution --hash ABC123DEF456

# Export attribution data as JSON
atomic attribution --output-format json --limit 100

# Channel-specific attribution analysis
atomic attribution --channel main --stats --providers

# Smart conflict resolution based on attribution (planned)
atomic resolve --prefer-human    # Prefer human-authored changes
atomic resolve --prefer-ai-high-confidence  # Prefer high-confidence AI
```

**Phase 4 - Distributed Attribution**:
```bash
# Attribution travels automatically during sync
atomic push origin main  # Pushes patches with full attribution metadata
atomic pull origin main  # Receives attribution from remote repositories

# Cross-repository attribution tracking
atomic attribution sync-stats  # Aggregate attribution across team repos
```

**Phase 5 - AI Development Analytics**:
```bash
# Team AI usage insights
atomic analytics team-ai-usage --project myproject
atomic analytics model-performance --provider openai
atomic analytics human-ai-collaboration --time-range 30d

# Export for compliance and reporting
atomic attribution export --format json --compliance-report
```

### Why Git-Based Systems Fail for AI Development

Traditional snapshot-based version control (Git) cannot handle the semantic complexity of AI-assisted development:

#### **The Snapshot Problem**
- **Git tracks states**, not semantic changes
- Attribution is commit-level metadata that gets lost during complex merges
- No mathematical guarantees about attribution preservation
- External attribution systems don't distribute with code changes

#### **The AI Challenge**
Modern AI development requires tracking:
- Multi-turn AI collaborations on single semantic changes
- Human modifications of AI suggestions with confidence scoring
- Collaborative workflows between multiple AI models
- Attribution that survives distributed team merges

#### **Why Semantic Changes Matter**
```
Git: "Alice made commit abc123" ‚ùå Lost during merge
Atomic: "Lines 15-30 were AI-generated by GPT-4 with 94% confidence,
         then human-modified by Alice, preserving semantic meaning" ‚úÖ
```

#### **The Hidden AI Development Problem: Attribution Analytics**

Atomic reveals AI development patterns that Git-based systems completely miss:

**Git's Blind Spot**: Git only shows successful commits - it has no visibility into:
- Failed AI attempts that were abandoned
- Experimental branches that never shipped
- The true cost of AI-assisted development iteration

**Atomic's Advantage**: Our patch-based architecture tracks ALL changes ever created:
- **Channel Changes**: What actually shipped to production
- **Filesystem Changes**: Every attempt, experiment, and iteration
- **Attribution Delta**: The difference reveals critical AI development insights

```bash
# Future Analytics (Phase 5)
$ atomic attribution analytics --experimentation

AI Development Efficiency Report:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Total Changes Created:     847
Shipped to Channel:        203  (24% success rate)  
Abandoned Experiments:     644  (76% iteration cost)

AI-Assisted Analysis:
‚îú‚îÄ AI Attempts:           521  (61% of all attempts)
‚îú‚îÄ AI Shipped:            127  (24% AI success rate)
‚îú‚îÄ AI Abandoned:          394  (76% AI waste)
‚îî‚îÄ AI Iteration Ratio:    4.1x (vs 3.2x human)

Business Intelligence:
‚Ä¢ AI generates 2.3x more experiments than humans
‚Ä¢ But ships at same 24% rate - hidden productivity cost
‚Ä¢ GPT-4 has 31% ship rate vs Claude-3 at 18%
‚Ä¢ AI review phase increases ship rate by 73%

Recommendation: Implement AI confidence thresholds
Changes with >85% AI confidence have 67% ship rate
```

**Why This Matters for Business**:
- **True ROI Analysis**: Understand the real cost of AI-assisted development
- **Model Comparison**: Which AI providers actually improve productivity vs. just increase churn
- **Process Optimization**: Identify successful vs. wasteful AI development patterns
- **Quality Prediction**: Predict change success before code review based on attribution patterns

**The Future is Data-Driven Development**: Understanding not just what shipped, but what didn't ship and why. Only Atomic's mathematical approach to change tracking can provide this level of insight into the AI development process.

**The Future is Agentic**: AI agents need to understand *what changed* and *why*, not just *who made a commit*. Only patch-based systems can provide this semantic understanding that survives distributed operations.

### Real-World Attribution Examples

```bash
# Scenario 1: AI generates initial code, human refines it
atomic record --ai-assisted \
  --ai-provider openai \
  --ai-model gpt-4 \
  --ai-suggestion-type partial \
  --ai-confidence 0.82 \
  -m "AI generated user auth, human added error handling"

# Scenario 2: Human writes code, AI reviews and suggests improvements
atomic record --ai-assisted \
  --ai-provider github \
  --ai-model copilot \
  --ai-suggestion-type review \
  --ai-confidence 0.91 \
  -m "Human implementation, AI suggested performance optimizations"

# Scenario 3: Collaborative back-and-forth development
export ATOMIC_AI_REVIEW_TIME=1800  # 30 minutes of human review
atomic record --ai-assisted \
  --ai-provider anthropic \
  --ai-model claude-3 \
  --ai-suggestion-type collaborative \
  -m "Complex algorithm developed through human-AI collaboration"

# Scenario 4: Complete AI generation with confidence tracking
atomic record --ai-assisted \
  --ai-provider openai \
  --ai-model gpt-4 \
  --ai-suggestion-type complete \
  --ai-confidence 0.95 \
  -m "AI generated entire test suite"

# Scenario 5: AI-inspired human implementation
atomic record --ai-assisted \
  --ai-provider github \
  --ai-model copilot \
  --ai-suggestion-type inspired \
  --ai-confidence 0.73 \
  -m "Implemented caching based on AI architectural suggestions"

# Scenario 6: AI refactoring of existing code
atomic record --ai-assisted \
  --ai-provider anthropic \
  --ai-model claude-3 \
  --ai-suggestion-type refactor \
  --ai-confidence 0.89 \
  -m "AI refactored legacy code for better performance"

# Scenario 7: Environment-based attribution (no CLI flags needed)
export ATOMIC_AI_ENABLED=true
export ATOMIC_AI_PROVIDER=openai
export ATOMIC_AI_MODEL=gpt-4
export ATOMIC_AI_SUGGESTION_TYPE=collaborative
export ATOMIC_AI_CONFIDENCE=0.87
export ATOMIC_AI_TOKEN_COUNT=3200
atomic record -m "Feature developed with configured AI assistance"

# Scenario 8: Mixed development with detailed tracking
export ATOMIC_AI_REVIEW_TIME=2700  # 45 minutes human review
export ATOMIC_AI_TEMPERATURE=0.3   # Low temperature for consistency
export ATOMIC_AI_MAX_TOKENS=8000   # Large context window
atomic record --ai-assisted \
  --ai-provider openai \
  --ai-model gpt-4 \
  --ai-suggestion-type collaborative \
  -m "Database migration with extensive AI-human collaboration"
```

These attributions become permanent parts of the patch metadata, traveling through merges, conflicts, and distribution across teams.

## Project Structure

The project is organized into several key components, each serving a specific purpose:

### Core Components

- `atomic/`: The main executable crate containing the command-line interface and core functionality
  - `src/`: Source code for the main binary
  - `tests/`: Integration tests

- `libatomic/`: The core library implementing the fundamental VCS operations
  - Contains the core data structures and algorithms
  - Implements the mathematical theory of changes and conflicts

### Supporting Libraries

- `atomic-macros/`: Custom derive macros and procedural macros used throughout the project
- `atomic-config/`: Configuration management and settings handling
- `atomic-repository/`: Repository management and operations
- `atomic-identity/`: User identity and authentication handling
- `atomic-interaction/`: User interaction and CLI interface components
- `atomic-remote/`: Remote repository operations and synchronization

### Development and Build

- `contrib/`: Additional contribution-related resources
- `flake.nix`, `shell.nix`: Nix build configurations for reproducible builds
- `Cargo.toml`: Rust workspace and dependency management
- `rustfmt.toml`: Rust code formatting configuration

## Key Features

- **Mathematically Sound**: Based on a formal theory of asynchronous work
- **AI Attribution**: First-class tracking of AI vs human contributions at the semantic level
- **Conflict Resolution**: Smart conflict detection and resolution with attribution context
- **Channel System**: Advanced branching system with commutative changes
- **Distributed Attribution**: Attribution metadata travels with patches automatically
- **Git Integration**: Optional Git repository import feature
- **Fast Performance**: Optimized for speed and efficiency

## Getting Started

### Installation

```bash
# Clone the repository
git clone https://github.com/castingclouds/atomic
cd atomic

# Build the project
cargo build --release

# Install to make the binary available in your PATH
# This ensures you're using the correct version
cargo install --path atomic --force
```

> **‚ö†Ô∏è Important:** After building a release version, always run `cargo install --path atomic --force` to update the binary in your PATH (`~/.cargo/bin/atomic`). Otherwise, you may continue using an older installed version instead of your newly built one.
>
> To verify you're using the correct binary:
> ```bash
> which atomic  # Should point to ~/.cargo/bin/atomic
> ls -lh ~/.cargo/bin/atomic  # Check the timestamp matches your build
> ```

### Basic Commands

#### Create a Repository
```bash
atomic init
```

#### Track Files
```bash
# Track all files in a folder
atomic rec that_folder

# Add specific files
atomic add these_files
```

#### Record Changes
```bash
# Standard recording
atomic rec

# Standard recording with message
atomic record -m "Add new feature"

# Interactive editing of changes before recording
atomic record --edit

# With AI attribution (new!)
atomic record --ai-assisted --ai-provider openai --ai-model gpt-4 -m "AI-assisted feature implementation"

# Complete AI attribution with all options
atomic record \
  --ai-assisted \
  --ai-provider anthropic \
  --ai-model claude-3 \
  --ai-suggestion-type collaborative \
  --ai-confidence 0.92 \
  --message "Refactor authentication system with AI assistance"

# Record with specific author and timestamp
atomic record --author "Alice <alice@company.com>" --timestamp "2024-01-15T10:30:00Z" -m "Fix critical bug"

# Record to specific channel
atomic record --channel feature-branch -m "Add new functionality"

# Amend the last change instead of creating new one
atomic record --amend -m "Updated commit message"

# Record specific files/directories only
atomic record src/auth/ tests/auth/ -m "Authentication changes only"

# Use Patience diff algorithm instead of Myers
atomic record --patience -m "Better diff for this change"

# Record with specific identity
atomic record --identity dev-key -m "Sign with development key"
```

#### Collaborate
```bash
# Clone a repository
atomic clone <repository-url>

# Push changes
atomic push

# Pull changes
atomic pull
```

### Working with Channels

Channels in Atomic are different from Git branches. They are pointers to sets of changes, where:
- Independent changes commute naturally
- Conflict resolution is change-based, not branch-based
- Conflict resolutions are shared across all channels

### Shell Prompt Integration

Display the current channel in your terminal prompt, similar to how Git shows branches:

```bash
# Source the prompt script in your ~/.bashrc or ~/.zshrc
source /path/to/atomic/contrib/atomic-prompt.sh
PS1='$(atomic_prompt)\w\$ '

# Or use the command directly in custom prompts
atomic prompt                    # Output: [main]
atomic prompt --channel-only     # Output: main
atomic prompt --format "‚öõ {channel}"  # Output: ‚öõ main
```

**Features:**
- üöÄ Fast performance with caching (~5-15ms first call, <1ms cached)
- üé® Automatic color detection
- ‚öôÔ∏è Customizable format strings
- üêö Support for Bash, Zsh, and Fish shells
- üìù Configuration via `~/.config/atomic/config.toml`

**Quick Start:**
```bash
# Run the demo to see it in action
bash contrib/prompt-demo.sh

# For detailed documentation
cat contrib/PROMPT_INTEGRATION.md
```

**Example prompts:**
```bash
[main] ~/code/project $                    # Minimal
[main] user@host:~/code/project $          # Full
[project:main] ~/code/project $            # With repository
‚öõ main ~/code/project $                    # Custom symbol
```

**Configuration:**
```toml
# ~/.config/atomic/config.toml
[prompt]
enabled = true
format = "[{channel}]"
show_repository = false
```

## Advanced Features

### Git Import
When compiled with `--features git`, Atomic can import Git repositories:
```bash
atomic git import <git-repo-path>
```

### History Management
```bash
# Reset to last recorded version
atomic reset

# Remove changes from history
atomic unrecord PREFIX_OF_CHANGE_HASH
```

## Server Setup and Remote Connections

Atomic supports multiple ways to host and connect to repositories, including SSH and HTTP protocols.

### Setting Up a Server

#### SSH Server Setup

1. Install Atomic on your server:
```bash
cargo install atomic
```

2. Create a new repository on the server:
```bash
mkdir /path/to/repo
cd /path/to/repo
atomic init
```

3. Configure SSH access:
   - Ensure SSH is properly configured on your server
   - Add user public keys to `~/.ssh/authorized_keys`
   - Set appropriate permissions:
```bash
chmod 700 ~/.ssh
chmod 600 ~/.ssh/authorized_keys
```

#### HTTP Server Setup

For HTTP-based repositories, you'll need to set up a web server (like nginx) with the following configuration:

1. Install and configure your web server
2. Configure the repository location:
```nginx
server {
    listen 80;
    server_name your.domain.com;

    location /repos {
        root /path/to/atomic/repos;
        autoindex on;
        # Allow Atomic protocol methods
        dav_methods PUT DELETE MKCOL COPY MOVE;
        # Allow Atomic headers
        add_header Access-Control-Allow-Headers "Authorization, Content-Type";
        add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE";
    }
}
```

### Connecting to Remote Repositories

#### Configure Remote Repositories

1. SSH Remote:
```bash
# Add a remote repository
atomic remote add origin ssh://user@host/path/to/repo

# Or with a custom port
atomic remote add origin ssh://user@host:2222/path/to/repo
```

2. HTTP Remote:
```bash
# Add an HTTP remote
atomic remote add origin http://your.domain.com/repos/myrepo

# Add an HTTPS remote with authentication
atomic remote add origin https://user@your.domain.com/repos/myrepo
```

#### Working with Remotes

```bash
# List configured remotes
atomic remote list

# Push changes to a remote
atomic push origin main

# Pull changes from a remote
atomic pull origin main

# Clone a remote repository
atomic clone ssh://user@host/path/to/repo
```

### Authentication

1. SSH Authentication:
   - Uses standard SSH key-based authentication
   - Configure keys in `~/.ssh/id_rsa` or use SSH agent
   - Supports custom SSH configurations in `~/.ssh/config`

2. HTTP Authentication:
   - Basic authentication with username/password
   - Token-based authentication
   - Custom headers can be configured in `.atomic/config`:
```toml
[remote.origin]
http = "https://your.domain.com/repos/myrepo"
headers.Authorization = "Bearer your-token"
```

### Security Best Practices

1. Always use HTTPS or SSH for remote repositories
2. Keep your SSH keys secure and use passphrase protection
3. Regularly update your Atomic installation
4. Use specific user accounts for repository access
5. Implement proper backup strategies for your repositories

## Storage Architecture

Atomic uses [Sanakirja](https://docs.rs/sanakirja) as its underlying storage engine, which is a high-performance embedded database designed specifically for version control systems. Here's how the storage system works:

### Database Structure

The repository data is stored in a structured database format with several key components:

- **Pristine Store**: The core database that maintains the repository's internal state
  - Stores the directed acyclic graph (DAG) of changes
  - Manages channel states and their relationships
  - Handles file metadata and inode mappings

### Key Database Components

1. **Channel Storage**:
   - Graph database for storing vertices and edges of changes
   - Change tracking with timestamps and merkle trees
   - State management for different channels

2. **File System Mapping**:
   - Inode-based file tracking
   - Path-to-inode mappings
   - File position tracking in the change history

3. **Change Management**:
   - Internal and external change tracking
   - Dependency graphs between changes
   - Partial change state management

### Performance Characteristics

- **Efficient Storage**: Uses memory-mapped files for fast access
- **Transactional Safety**: All operations are ACID compliant
- **Optimized for VCS**: Specifically designed for version control operations
  - Fast graph traversal for history operations
  - Efficient handling of concurrent changes
  - Optimized for append-heavy workloads

The storage system is crucial for Atomic's ability to handle distributed version control efficiently while maintaining data integrity and supporting its mathematical model of changes.

## Contributing

We welcome all contributions. Moreover, as this projects aims at making it easier to collaborate with others (we're getting there), we obviously value mutual respect and inclusiveness above anything else.

Moreover, since this is a Rust project, we ask contributors to run `cargo fmt` on their code before recording changes. This can be done automatically by adding the following lines to the repository's `.atomic/config`:

```
[hooks]
record = [ "cargo fmt" ]
```

## License

This project is licensed under GPL-2.0. See the `COPYING` file for details.

## The Future of Version Control in the AI Era

As AI becomes integral to software development, version control systems must evolve beyond simple commit tracking. Atomic's patch-based architecture provides the mathematical foundation needed for:

- **Semantic Change Tracking**: Understanding what changed, not just when
- **AI-Human Collaboration**: Nuanced attribution for collaborative development
- **Distributed AI Workflows**: Attribution that survives complex distributed operations
- **Agentic Development**: AI agents that can understand change context and history
- **Attribution Analytics**: Complete visibility into AI development patterns and true productivity costs

### Next Steps: Revolutionary Attribution Analytics

**Phase 5 Vision**: Atomic will be the first VCS to provide complete AI development intelligence by leveraging our unique ability to track ALL changes (not just shipped commits):

#### Business Intelligence Features (Coming Soon)
- **True AI ROI Analysis**: Track the hidden cost of AI experimentation vs. shipped value
- **Model Performance Comparison**: Which AI providers actually improve productivity vs. increase churn
- **Development Process Optimization**: Identify successful patterns in AI-assisted workflows
- **Quality Prediction**: Predict change success rates based on attribution patterns before code review
- **Team AI Efficiency Scoring**: Understand which developers effectively leverage AI assistance

#### The Git Gap That Only Atomic Can Fill
```
Git Visibility:     [Commit A] ‚Üí [Commit B] ‚Üí [Commit C]
                    ‚Üë 3 successful commits

Atomic Visibility: [Commit A] ‚Üí [15 failed attempts] ‚Üí [Commit B] ‚Üí [8 experiments] ‚Üí [Commit C]
                    ‚Üë Complete development process with attribution for every attempt

Analytics Gold Mine: 23 total changes, 3 shipped (13% success rate)
- AI attempts: 18 (78% of all attempts)
- AI shipped: 2 (11% AI success rate)  
- Human shipped: 1 (20% human success rate)
- Business insight: AI increases experimentation 4x but success rate needs improvement
```

This level of development process intelligence is impossible with snapshot-based systems. Only Atomic's mathematical approach to change tracking can reveal the true patterns of AI-assisted development, making it the essential VCS for the AI era.

Traditional snapshot-based systems like Git were designed for a world of human-only development. The future requires systems that can handle the semantic complexity of AI-assisted development while maintaining mathematical correctness and providing unprecedented insight into development processes.

**Atomic is building that future.**

## Acknowledgements

Special thanks to [Pijul](https://pijul.org) for their original work, which served as the foundation to the Atomic project.
